import sys
import os
import glob
import zipfile
import pandas as pd
import subprocess
from lxml import etree
import docx
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_COLOR_INDEX
from datetime import datetime

# --- –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
BACKEND_ROOT = os.path.dirname(CURRENT_DIR)
if BACKEND_ROOT not in sys.path:
    sys.path.insert(0, BACKEND_ROOT)

try:
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞—à —Ç–µ–∫—É—â–∏–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä (Predictor)
    from app.services.style_extractor import style_extractor
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    sys.exit(1)

TEST_DOCS_DIR = os.path.join(CURRENT_DIR, "test_docs")
REPORTS_DIR = os.path.join(CURRENT_DIR, "validation_reports")
os.makedirs(REPORTS_DIR, exist_ok=True)

# --- 1. DATA COLLECTION: XML GROUND TRUTH (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô) ---
class XmlFeatureExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç '—á–∏—Å—Ç—ã–µ' –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ XML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã DOCX.
    –≠—Ç–æ –Ω–∞—à–∞ '–ò—Å—Ç–∏–Ω–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–Ω—Å—Ç–∞–Ω—Ü–∏–∏' (Ground Truth).
    """
    def extract(self, docx_path):
        ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
        features = []
        
        try:
            with zipfile.ZipFile(docx_path) as z:
                xml_content = z.read('word/document.xml')
                tree = etree.fromstring(xml_content)
                
                # –ò—â–µ–º –≤—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                for p in tree.xpath('//w:p', namespaces=ns):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç (—Å–æ–±–∏—Ä–∞–µ–º –∏–∑ –≤—Å–µ—Ö run-–æ–≤)
                    texts = p.xpath('.//w:t/text()', namespaces=ns)
                    full_text = "".join(texts).strip()
                    
                    # –ß—Ç–æ–±—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å RAG, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ, –µ—Å–ª–∏ RAG –∏—Ö –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç
                    # (–í style_extractor –º—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ, –µ—Å–ª–∏ –Ω–µ—Ç —Ä–∞–∑—Ä—ã–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
                    # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ–∫–∞ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ
                    if not full_text:
                        continue

                    # 1. –°–≤–æ–π—Å—Ç–≤–∞ –∞–±–∑–∞—Ü–∞ (–°—Ç–∏–ª—å)
                    pPr = p.find('w:pPr', namespaces=ns)
                    style_id = "Normal" # Default
                    if pPr is not None:
                        style_node = pPr.find('w:pStyle', namespaces=ns)
                        if style_node is not None:
                            style_id = style_node.get(f"{{{ns['w']}}}val")

                    # 2. –°–≤–æ–π—Å—Ç–≤–∞ –ø–µ—Ä–≤–æ–≥–æ Run (–ñ–∏—Ä–Ω–æ—Å—Ç—å, –†–∞–∑–º–µ—Ä) - Direct Formatting
                    is_bold_xml = False
                    font_size_xml = "Inherited"
                    
                    runs = p.xpath('.//w:r', namespaces=ns)
                    if runs:
                        rPr = runs[0].find('w:rPr', namespaces=ns)
                        if rPr is not None:
                            # –ñ–∏—Ä–Ω–æ—Å—Ç—å (<w:b/> —Å—É—â–µ—Å—Ç–≤—É–µ—Ç?)
                            if rPr.find('w:b', namespaces=ns) is not None:
                                is_bold_xml = True
                            # –†–∞–∑–º–µ—Ä (<w:sz w:val="24"/>)
                            sz = rPr.find('w:sz', namespaces=ns)
                            if sz is not None:
                                val = sz.get(f"{{{ns['w']}}}val")
                                if val and val.isdigit():
                                    font_size_xml = str(int(val) / 2) # XML —Ö—Ä–∞–Ω–∏—Ç –≤ –ø–æ–ª-–ø—É–Ω–∫—Ç–∞—Ö

                    features.append({
                        "text_snippet": full_text[:50], # –î–ª—è —Å–≤–µ—Ä–∫–∏
                        "full_text_len": len(full_text),
                        "xml_style": style_id,
                        "xml_bold": is_bold_xml,
                        "xml_size": font_size_xml
                    })
        except Exception as e:
            print(f"XML Parsing Error in {docx_path}: {e}")
            
        return features

# --- 2. CORE VALIDATOR LOGIC ---
class WorkflowValidator:
    def __init__(self):
        self.xml_parser = XmlFeatureExtractor()
    
    def normalize_style(self, name):
        """–ü—Ä–∏–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∏–ª–µ–π –∫ –æ–±—â–µ–º—É –≤–∏–¥—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not name: return "normal"
        return str(name).lower().replace(" ", "").replace("heading", "heading").replace("title", "title")

    def run_validation(self):
        docx_files = glob.glob(os.path.join(TEST_DOCS_DIR, "*.docx"))
        if not docx_files:
            print("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–æ–≤!")
            return

        all_diffs = []

        print(f"üöÄ –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ {len(docx_files)} —Ñ–∞–π–ª–∞—Ö...")

        for file_path in docx_files:
            filename = os.path.basename(file_path)
            
            # A. GROUND TRUTH (XML)
            xml_data = self.xml_parser.extract(file_path)
            
            # B. RAG PREDICTION (StyleExtractor)
            # –í–ê–ñ–ù–û: StyleExtractor –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            rag_data = style_extractor.parse_docx(file_path)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º RAG –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å <PAGE_BREAK> –∏ –ø—É—Å—Ç—ã–µ, 
            # —á—Ç–æ–±—ã —Å–ø–∏—Å–∫–∏ —Å–æ–≤–ø–∞–ª–∏ –ø–æ –¥–ª–∏–Ω–µ (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è)
            rag_data_clean = [x for x in rag_data if x['text'] != "<PAGE_BREAK>" and x['text'].strip()]

            # C. DIFFING (–°—Ä–∞–≤–Ω–µ–Ω–∏–µ)
            # –ú—ã –∏–¥–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è, —á—Ç–æ –ø–æ—Ä—è–¥–æ–∫ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω
            limit = min(len(xml_data), len(rag_data_clean))
            
            print(f"üìÑ {filename}: XML –Ω–∞—à—ë–ª {len(xml_data)} –±–ª–æ–∫–æ–≤, RAG –Ω–∞—à—ë–ª {len(rag_data_clean)}. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º {limit}...")

            file_errors = []

            for i in range(limit):
                xml_item = xml_data[i]
                rag_item = rag_data_clean[i]
                rag_meta = rag_item['metadata']

                # --- –ü–†–ê–í–ò–õ–ê –°–†–ê–í–ù–ï–ù–ò–Ø ---
                
                # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è
                s_xml = self.normalize_style(xml_item['xml_style'])
                s_rag = self.normalize_style(rag_meta['style_name'])
                
                # RAG –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫, –µ—Å–ª–∏ –≤ XML —ç—Ç–æ Heading
                # –ò–ª–∏ –µ—Å–ª–∏ RAG —Å–∞–º —Ä–µ—à–∏–ª, —á—Ç–æ —ç—Ç–æ Header (–ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ —Ä–∞–∑–º–µ—Ä–∞)
                is_error = False
                error_type = ""

                # –õ–æ–≥–∏–∫–∞ –æ—à–∏–±–∫–∏: –í XML —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∞ RAG –≥–æ–≤–æ—Ä–∏—Ç Normal
                if "heading" in s_xml and "heading" not in s_rag and not rag_meta['is_header']:
                    is_error = True
                    error_type = "Missed Header"
                
                # –õ–æ–≥–∏–∫–∞ –æ—à–∏–±–∫–∏: –í XML —ç—Ç–æ Normal, –∞ RAG –ø—Ä–∏–¥—É–º–∞–ª Heading (—Ö–æ—Ç—è —à—Ä–∏—Ñ—Ç –º–µ–ª–∫–∏–π)
                elif "normal" in s_xml and "heading" in s_rag:
                    # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –æ—à–∏–±–∫–æ–π, –µ—Å–ª–∏ —Å—Ä–∞–±–æ—Ç–∞–ª–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–∞!
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É:
                    if not rag_meta['is_header']: # –ï—Å–ª–∏ RAG –ø–æ–º–µ—Ç–∏–ª —ç—Ç–æ –∫–∞–∫ Header —Ç–æ–ª—å–∫–æ –ø–æ –∏–º–µ–Ω–∏ —Å—Ç–∏–ª—è, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç
                         is_error = True
                         error_type = "Hallucinated Header"

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                all_diffs.append({
                    "file": filename,
                    "index": i,
                    "text": xml_item['text_snippet'],
                    "xml_style": xml_item['xml_style'],
                    "rag_style": rag_meta['style_name'],
                    "rag_is_header_flag": rag_meta['is_header'],
                    "status": "FAIL" if is_error else "PASS",
                    "error_type": error_type
                })
                
                if is_error:
                    file_errors.append(i) # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å –∞–±–∑–∞—Ü–∞ —Å –æ—à–∏–±–∫–æ–π

            # D. REPORTING (–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—à–∏–±–æ–∫ –≤ PDF)
            if file_errors:
                self.create_error_pdf(file_path, file_errors, rag_data_clean, filename)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ CSV
        df = pd.DataFrame(all_diffs)
        csv_path = os.path.join(REPORTS_DIR, f"validation_benchmark_{datetime.now().strftime('%H%M')}.csv")
        df.to_csv(csv_path, index=False)
        
        # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        error_count = len(df[df['status'] == 'FAIL'])
        total_count = len(df)
        print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ê–õ–ò–î–ê–¶–ò–ò ===")
        print(f"–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {total_count}")
        print(f"–û—à–∏–±–æ–∫ –Ω–∞–π–¥–µ–Ω–æ: {error_count}")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {((total_count - error_count) / total_count * 100):.2f}%")
        print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {csv_path}")
        print(f"PDF-—Ä–µ–Ω—Ç–≥–µ–Ω—ã —Å –æ—à–∏–±–∫–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {REPORTS_DIR}")

    def create_error_pdf(self, original_path, error_indices, rag_data, filename):
        """–°–æ–∑–¥–∞–µ—Ç PDF, –≥–¥–µ –ü–û–î–°–í–ï–ß–ï–ù–´ –ö–†–ê–°–ù–´–ú —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏"""
        try:
            doc = docx.Document(original_path)
            
            # –ù—É–∂–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è. –≠—Ç–æ —Å–ª–æ–∂–Ω–æ –≤ docx –Ω–∞–ø—Ä—è–º—É—é, 
            # –ø–æ—ç—Ç–æ–º—É –º—ã –∏–¥–µ–º –ø–æ —Å—á–µ—Ç—á–∏–∫—É –Ω–µ–ø—É—Å—Ç—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            non_empty_idx = 0
            
            for para in doc.paragraphs:
                if not para.text.strip(): continue
                
                # –ï—Å–ª–∏ —ç—Ç–æ—Ç –∏–Ω–¥–µ–∫—Å –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ –æ—à–∏–±–æ–∫
                if non_empty_idx in error_indices:
                    # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∫—Ä–∞—Å–Ω—ã–º —Ñ–æ–Ω–æ–º
                    for run in para.runs:
                        run.font.highlight_color = WD_COLOR_INDEX.RED
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π RAG vs XML
                    rag_info = rag_data[non_empty_idx]
                    style_guess = rag_info['metadata']['style_name']
                    is_header = rag_info['metadata']['is_header']
                    
                    msg = f"[ERROR] RAG thought: {style_guess} (Header={is_header})"
                    
                    # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–º–µ—Ç–∫—É
                    p_new = para.insert_paragraph_before(msg)
                    for r in p_new.runs: 
                        r.font.size = Pt(9)
                        r.font.bold = True
                        r.font.color.rgb = RGBColor(255, 0, 0)
                
                non_empty_idx += 1
                
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
            temp_docx = os.path.join(REPORTS_DIR, f"FAILURES_{filename}")
            doc.save(temp_docx)
            
            subprocess.run([
                "soffice", "--headless", "--convert-to", "pdf",
                temp_docx, "--outdir", REPORTS_DIR
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # os.remove(temp_docx)
            
        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å PDF –æ—Ç—á–µ—Ç –¥–ª—è {filename}: {e}")

if __name__ == "__main__":
    validator = WorkflowValidator()
    validator.run_validation()